{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81c0e7cc-7ecd-400f-995b-aeb47b67d3a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Install the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d8f003b-c804-46d3-b8f8-acfca8c29411",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatabricks-feature-engineering 0.2.1 requires pyspark<4,>=3.1.2, which is not installed.\nydata-profiling 4.2.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.8.2 which is incompatible.\nspacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U gradio==4.31.4 boto3==1.34.108 langchain==0.2.0 langchain-community==0.2.0 pypdf==4.2.0 sentence-transformers==2.7.0 chromadb mlflow==2.11.0 -q\n",
    "# %pip install -U gradio==4.31.4 boto3==1.34.108 langchain==0.2.0 langchain-community==0.2.0 pypdf==4.2.0 sentence-transformers==2.7.0 faiss-cpu==1.8.0 mlflow==2.11.0 -q\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a20ae898-f9a1-4b81-b066-5eb9ddcc85a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This Python code snippet imports various classes and functions from the langchain_community and langchain_text_splitters packages, which are likely part of a larger framework for working with language, documents, and embeddings in machine learning or natural language processing (NLP) applications. Here's a breakdown of what each import does:\n",
    "\n",
    "PyPDFLoader: This class is imported from langchain_community.document_loaders. It is likely used to load or parse PDF documents, making their content accessible for processing or analysis.\n",
    "\n",
    "CharacterTextSplitter and RecursiveCharacterTextSplitter: These classes are imported from langchain_text_splitters. They are probably used to split text into smaller pieces, such as sentences, words, or characters. The \"RecursiveCharacterTextSplitter\" might offer a more complex or hierarchical way of splitting text compared to the straightforward \"CharacterTextSplitter\".\n",
    "\n",
    "SentenceTransformerEmbeddings and HuggingFaceEmbeddings: These classes are imported from langchain_community.embeddings.sentence_transformer. They are likely used to generate embeddings for text. Embeddings are dense vector representations of text that capture semantic meaning. \"SentenceTransformerEmbeddings\" suggests the use of the Sentence Transformers library, which is known for producing high-quality sentence-level embeddings. \"HuggingFaceEmbeddings\" implies integration with Hugging Face's Transformers library, a popular choice for various NLP tasks and transformer-based models.\n",
    "\n",
    "Chroma: This class is imported from langchain_community.vectorstores. It probably provides functionality for storing and managing the vector embeddings generated by the aforementioned embedding classes. \"Vectorstores\" are typically used to efficiently search and retrieve similar embeddings, facilitating tasks like semantic search, clustering, and more.\n",
    "\n",
    "Overall, this code snippet sets up the groundwork for a project that involves processing PDF documents, splitting text into manageable pieces, generating meaningful embeddings for those pieces, and storing those embeddings in a way that they can be efficiently accessed and used for further analysis or machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf6bc772-0e3f-4875-a555-ca2765db00e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "  SentenceTransformerEmbeddings, HuggingFaceEmbeddings\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f540198-4c92-41eb-9126-0b2680fe83ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Create Index Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87dac670-615b-48fd-8737-ec1d56ecb9a2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Load pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abc2c8a7-9b05-46c5-8366-d91553a06dc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"/Volumes/sarbani-rag-dbdemo/customer_support_bot/pdf_insurance/insurance-agent-faq.pdf\")\n",
    "pages = loader.load_and_split(text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200))\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c294a307-cdf0-43a6-92b7-c457d2237310",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Volumes/sarbani-rag-dbdemo/customer_support_bot/pdf_insurance/insurance-agent-faq.pdf', 'page': 0}, page_content='term plans, these plans are valid for the entirety of the policyholder’s life. Both types of policies have their own perks. You must assess your needs ﬁrst to decide which is better. If you seek high coverage at low premium rates, then term plans are a better option. However, if you want life cover as well as savings beneﬁts with a longer tenure, a whole life plan will be a perfect pick. InsuranceLife InsuranceCan I get life insurance at 62 years?Yes, you can buy life insurance at 62 years. Most life insurance policies have a maximum entry age ranging between 55 years and 60 years. However, there are numerous policies that are designed speciﬁcally for senior citizens. Such plans are useful for individuals who haven’t invested in a plan earlier in life. Certain plans for senior citizens also oﬀer retirement beneﬁts and pay outs. InsuranceLife InsuranceWhy do term insurance policies oﬀer higher life coverage than other types of insurance policies?Premiums paid by a term insurance')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "472588a7-3f19-4b8d-be3d-c6e2d3ac3d4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 22:57:35.809073: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2024-07-12 22:57:35.855114: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 22:57:35.855159: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 22:57:35.855186: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-07-12 22:57:35.863716: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Initialize an embedding function using the SentenceTransformer model \"all-MiniLM-L6-v2\"\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a Chroma object from the loaded document pages with the specified embedding function\n",
    "db = Chroma.from_documents(pages, embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4eeb7589-5b88-4173-b468-6b3ecb1e72c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Read part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2e57678-7899-4f46-a4ff-ef84dc5fde6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a retriever from the Chroma object with a specified number of documents to retrieve (k=2)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# Retrieve the top 2 documents relevant to the given query about life insurance costs and factors affecting the price\n",
    "docs = retriever.get_relevant_documents(\"What’s the Average Cost of a Life Insurance Plan and what Affects the Price? ?\")\n",
    "\n",
    "# Get the number of documents retrieved\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "509201a0-956f-4905-a706-ee57811fb705",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Loan Facility: People who obtain life insurance plans will have the option of borrowing money against it, which may assist them to cover unforeseen expenses as they progress through life without jeopardising the policy's bene ﬁts.\n Redemption of Mortgage: The ﬁnest tool for covering loans and mortgages taken out by the policyholder is a life insurance policy. The insurance can be used to pay oﬀ the loan or mortgage if there is ever an unanticipated circumstance that prevents the policyholder from being able to repay his or her loan or mortgage. In this case, the grieving family members will not be responsible for repayment.\nTax Beneﬁts: Life insurance policies oﬀer attractive tax beneﬁts and help you save a signiﬁcant amount of money which would otherwise be spent on taxes.\nWhat’s the Average Cost of a Life Insurance Plan and what Aﬀects the Price?' metadata={'page': 2, 'source': '/Volumes/sarbani-rag-dbdemo/customer_support_bot/pdf_insurance/insurance-agent-faq.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e1a9e2b-d97c-4841-bf6e-527d5323dce1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Generate Humanlike/Chat/any task using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "298df045-7b4c-472c-a543-38d15dd99b95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting langchain_openai\n  Using cached langchain_openai-0.1.16-py3-none-any.whl (46 kB)\nCollecting openai<2.0.0,>=1.32.0\n  Using cached openai-1.35.13-py3-none-any.whl (328 kB)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from langchain_openai) (0.2.17)\nCollecting tiktoken<1,>=0.7\n  Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.75 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain_openai) (0.1.85)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain_openai) (1.33)\nRequirement already satisfied: pydantic<3,>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain_openai) (2.8.2)\nRequirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain_openai) (23.2)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain_openai) (6.0)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.17->langchain_openai) (8.5.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.7.0)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.2.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.12.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (3.5.0)\nRequirement already satisfied: tqdm>4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.4)\nRequirement already satisfied: httpx<1,>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\nRequirement already satisfied: regex>=2022.1.18 in /databricks/python3/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2022.7.9)\nRequirement already satisfied: requests>=2.26.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (3.4)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (2022.12.7)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.17->langchain_openai) (2.4)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.17->langchain_openai) (3.10.6)\nRequirement already satisfied: annotated-types>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.17->langchain_openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.17->langchain_openai) (2.20.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.4)\nInstalling collected packages: tiktoken, openai, langchain_openai\n  Attempting uninstall: tiktoken\n    Found existing installation: tiktoken 0.5.2\n    Not uninstalling tiktoken at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c\n    Can't uninstall 'tiktoken'. No files were found to uninstall.\n  Attempting uninstall: openai\n    Found existing installation: openai 0.28.1\n    Not uninstalling openai at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c\n    Can't uninstall 'openai'. No files were found to uninstall.\nSuccessfully installed langchain_openai-0.1.16 openai-1.35.13 tiktoken-0.7.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_openai  # Install the langchain_openai package to use OpenAI models within the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16c19f8b-715a-48c9-aa13-f0f86f2c7912",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import AzureOpenAI, AzureChatOpenAI\n",
    "\n",
    "# azure_openai_llm = AzureChatOpenAI(\n",
    "#     openai_api_version=\"2023-05-15\",\n",
    "#     azure_deployment=\"dbdemo-gpt35\",\n",
    "#     model_name=\"gpt-35-turbo\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# # # llm = AzureChatOpenAI(\n",
    "# # #     deployment_name=\"dbdemo-gpt35\",\n",
    "# # #     model_name=\"gpt-35-turbo\",\n",
    "# # #     temperature=0,\n",
    "# # #     max_tokens=20\n",
    "# # # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0818d5bf-b0d5-4b54-8fb1-421e16c3df23",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Generate Humanlike/Chat/any task using hosted LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bb82a29-09a1-4653-bf97-e4bb58f58abe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2668253031794707>, line 4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#loader = PyPDFLoader(\"/Volumes/sarbani_dbrx_catalog/dbrx_llm_schema/customer_doc_demo/hdfc_news_release.pdf\")\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m loader \u001B[38;5;241m=\u001B[39m PyPDFLoader(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Volumes/sarbani_dbrx_catalog/dbrx_llm_schema/customer_doc_demo/hdfc_earning.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      5\u001B[0m pages \u001B[38;5;241m=\u001B[39m loader\u001B[38;5;241m.\u001B[39mload_and_split(text_splitter\u001B[38;5;241m=\u001B[39mRecursiveCharacterTextSplitter(chunk_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, chunk_overlap\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m))\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;28mlen\u001B[39m(pages)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-1136a816-43f9-4303-ba11-22501c337a95/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:182\u001B[0m, in \u001B[0;36mPyPDFLoader.__init__\u001B[0;34m(self, file_path, password, headers, extract_images)\u001B[0m\n",
       "\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
       "\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n",
       "\u001B[1;32m    180\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpypdf package not found, please install it with \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`pip install pypdf`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    181\u001B[0m     )\n",
       "\u001B[0;32m--> 182\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    183\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparser \u001B[38;5;241m=\u001B[39m PyPDFParser(password\u001B[38;5;241m=\u001B[39mpassword, extract_images\u001B[38;5;241m=\u001B[39mextract_images)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-1136a816-43f9-4303-ba11-22501c337a95/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:116\u001B[0m, in \u001B[0;36mBasePDFLoader.__init__\u001B[0;34m(self, file_path, headers)\u001B[0m\n",
       "\u001B[1;32m    114\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(temp_pdf)\n",
       "\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path):\n",
       "\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile path \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m is not a valid file or url\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path)\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: File path /Volumes/sarbani_dbrx_catalog/dbrx_llm_schema/customer_doc_demo/hdfc_earning.pdf is not a valid file or url"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "File path /Volumes/sarbani_dbrx_catalog/dbrx_llm_schema/customer_doc_demo/hdfc_earning.pdf is not a valid file or url"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-2668253031794707>, line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#loader = PyPDFLoader(\"/Volumes/sarbani_dbrx_catalog/dbrx_llm_schema/customer_doc_demo/hdfc_news_release.pdf\")\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m loader \u001B[38;5;241m=\u001B[39m PyPDFLoader(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Volumes/sarbani_dbrx_catalog/dbrx_llm_schema/customer_doc_demo/hdfc_earning.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m pages \u001B[38;5;241m=\u001B[39m loader\u001B[38;5;241m.\u001B[39mload_and_split(text_splitter\u001B[38;5;241m=\u001B[39mRecursiveCharacterTextSplitter(chunk_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, chunk_overlap\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m))\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mlen\u001B[39m(pages)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-1136a816-43f9-4303-ba11-22501c337a95/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:182\u001B[0m, in \u001B[0;36mPyPDFLoader.__init__\u001B[0;34m(self, file_path, password, headers, extract_images)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m    180\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpypdf package not found, please install it with \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`pip install pypdf`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    181\u001B[0m     )\n\u001B[0;32m--> 182\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparser \u001B[38;5;241m=\u001B[39m PyPDFParser(password\u001B[38;5;241m=\u001B[39mpassword, extract_images\u001B[38;5;241m=\u001B[39mextract_images)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-1136a816-43f9-4303-ba11-22501c337a95/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:116\u001B[0m, in \u001B[0;36mBasePDFLoader.__init__\u001B[0;34m(self, file_path, headers)\u001B[0m\n\u001B[1;32m    114\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(temp_pdf)\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path):\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile path \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m is not a valid file or url\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path)\n",
        "\u001B[0;31mValueError\u001B[0m: File path /Volumes/sarbani_dbrx_catalog/dbrx_llm_schema/customer_doc_demo/hdfc_earning.pdf is not a valid file or url"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from langchain.chat_models import ChatDatabricks\n",
    "\n",
    "# chat_model = ChatDatabricks(endpoint=\"databricks-mixtral-8x7b-instruct\", max_tokens=256)\n",
    "# print(chat_model.invoke('what is the banks yearly performence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf55dd45-12dd-4441-a3bc-79023d83c4f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ce9c355-b8f6-4f2c-b629-a92514e68320",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### I am using Databricks DBRX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e493979-dd6f-4615-9726-a288e280dc6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n* 'schema_extra' has been renamed to 'json_schema_extra'\n  warnings.warn(message, UserWarning)\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-c0b852a0-c1e1-4453-b60d-1e0f2c26c06c/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n  warn_deprecated(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chat model: Late charges on life insurance premiums refer to the additional fees that policyholders may incur if they fail to pay their premiums on time. The specifics of late charges can vary depending on the insurance provider and the policy agreement. Some providers may offer a grace period before applying late charges, while others may not. It's essential to review the policy documents or contact the insurance provider for accurate information regarding late charges.\n"
     ]
    }
   ],
   "source": [
    "# Import ChatDatabricks class from langchain_community.chat_models for chat model interactions\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "\n",
    "# Initialize the Databricks Foundation LLM model with a specific endpoint and max_tokens setting\n",
    "dbrx_chat_model = ChatDatabricks(endpoint=\"databricks-dbrx-instruct\", max_tokens=200)\n",
    "\n",
    "# Use the predict method of the chat model to ask a question and print the response\n",
    "print(f\"Test chat model: {dbrx_chat_model.predict('What are the Late Charges on Life Insurance Premiums?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59737b7c-3d81-40f4-af28-a6c07e163cf7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Create a QA Chain from Langchains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da292fd1-a662-4889-990f-4630e5bebbc9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fa6adc3-d03c-4964-aef3-c69707173a14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Initialize a RetrievalQA chain with a specific LLM, chain type, retriever, and option to return source documents\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=dbrx_chat_model,  # Use the previously initialized Databricks Foundation LLM model\n",
    "                                       chain_type=\"stuff\",  # Specify the type of chain to use (placeholder value)\n",
    "                                       retriever=retriever,  # Specify the retriever to use for fetching documents\n",
    "                                       return_source_documents=True)  # Option to return the documents used in generating the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc49fa4-24d4-4e6a-8182-3dd37f7bd007",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the query to be answered\n",
    "query = \"What are the Late Charges on Life Insurance Premiums?\"\n",
    "# Use the RetrievalQA chain to process the query and store the response\n",
    "llm_response = qa_chain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e6ffaac-7e57-4de7-a7c1-9871ef1dd4a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Late charges on life insurance premiums vary depending on the policy and the insurer. Policyholders will need to pay penalties for late charges, and the penalty amount can differ based on the duration for which the premium payment is due. To revive the policy through 'reinstatement', policyholders need to pay all the outstanding premiums, and applicable interest rates will be charged. It's important to note that late payment charges can be avoided by selecting the auto-debit option, setting reminder alerts before the premium payment date, keeping track of the reminders, and opting for yearly premium payment instead of monthly payments.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f4672f5-a335-47d4-ba96-b1b3007d5af9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n2\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_list = []\n",
    "for doc in llm_response['source_documents']:\n",
    "    # Print the current page number from the document's metadata\n",
    "    print(doc.metadata['page'])\n",
    "    # Increment the page number by 1\n",
    "    tmp = doc.metadata['page'] + 1\n",
    "    # Append the incremented page number to the page_list\n",
    "    page_list.append(tmp)\n",
    "    # The commented print statement below was likely used for debugging\n",
    "    #print(doc)\n",
    "\n",
    "# Return the list of incremented page numbers\n",
    "page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ed527ca-0ec6-4045-bbd0-8e30c74b230b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate a string of unique page numbers from page_list, separated by commas, and prefix it with 'Document Page Numbers ='\n",
    "doc_pages = 'Document Page Numbers =' + ','.join(set([str(pgno) for pgno in page_list]))\n",
    "\n",
    "# Generate a string of unique document source names from llm_response['source_documents'], separated by commas, and prefix it with 'Document ='\n",
    "doc_name = \"Document =\" + ','.join(set([str(doc.metadata['source']) for doc in llm_response['source_documents']]))\n",
    "\n",
    "# Generate a string of unique document page contents from llm_response['source_documents'], separated by a period and newline, and prefix it with 'Document Details ='\n",
    "doc_content = \"Document Details =\" + '.\\n'.join(set([str(doc.page_content) for doc in llm_response['source_documents']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a65fdc3c-b930-4d07-9c13-cf8ad99f5c8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Page Numbers =3\nDocument =/Volumes/sarbani-rag-dbdemo/customer_support_bot/pdf_insurance/insurance-agent-faq.pdf\n**********content*********\nDocument Details =Cash value divides your premium into two parts:\no   One portion helps in wealth creation and earns interest\no   While the other portion helps in covering the cost of ﬁnancial security\nOnce enough cash value has been accumulated it can be received at the time of maturity or apply for loan in case of emergencyInsuranceLife InsuranceWhat are the Late Charges on Life Insurance Premiums?Here are some details regarding late charges on life insurance premiums:\nPolicyholders will need to pay penalties on late charges on life insurance premiums\nThe penalty amount varies depending on policy and the insurer\nTo revive the policy through ‘reinstatement’, policyholders need to pay all the outstanding premiums with applicable interest rates will be applicable\nLate payment charges also depend on the duration for which premium payment is due.\nLate payment charges also depend on the duration for which premium payment is due\n Life insurance plan can be revived within ﬁve years of last premium paying dateInsuranceLife InsuranceHow Can You Avoid Paying Late Fees in Life Insurance?The following are some of the signiﬁcant points that you should remember to avoid paying late fees in life insurance:\nSelect auto-debit option so that you do not miss out on premium payments\nSelect reminder option before premium payment date to avoid delayed payment\nKeep track of the premium payment reminders\nOpt for yearly premium payment instead of monthly payments to avoid missing out on regular payments\nLife Insurance Exclusion\nThe exclusions under life insurance plans may diﬀer from one policy to another. However, there are certain exclusions that almost all policies agree with. Mentioned below are some important ones:\nDeath caused while performing criminal or unlawful activities\nDeath caused by man-made disasters like war, riot, etc.\n"
     ]
    }
   ],
   "source": [
    "# Print the string of unique page numbers\n",
    "print(doc_pages)\n",
    "# Print the string of unique document source names\n",
    "print(doc_name)\n",
    "# Print a separator for readability\n",
    "print(\"**********content*********\")\n",
    "# Print the string of unique document page contents\n",
    "print(doc_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53d4e0ec-3996-445e-99ba-ee1cd876eb9b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### GRADIO with PDF source location + page number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "461ec1f4-36ec-4eb4-ae51-d07436ebfd18",
     "showTitle": true,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://5fcd7e14c10ba5f235.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5fcd7e14c10ba5f235.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def question_answer(question, image):\n",
    "    # Process the question and image to get an answer and related document information\n",
    "    output = qa_chain(question)\n",
    "\n",
    "    page_list = []\n",
    "    for doc in output['source_documents']:\n",
    "        # Increment page number by 1 to adjust for zero-based indexing\n",
    "        tmp = doc.metadata['page'] + 1\n",
    "        page_list.append(tmp)\n",
    "\n",
    "    # Generate a string of unique page numbers, separated by commas\n",
    "    doc_pages = ','.join(set([str(pgno) for pgno in page_list]))\n",
    "    # Generate a string of unique document source names, separated by commas\n",
    "    doc_name = ','.join(set([str(doc.metadata['source']) for doc in output['source_documents']]))\n",
    "    # Generate a string of unique document page contents, separated by a period and newline\n",
    "    doc_content = '.\\n'.join(set([str(doc.page_content) for doc in output['source_documents']]))\n",
    "    \n",
    "    return output['result'], doc_pages, doc_name, doc_content\n",
    "\n",
    "# HTML content for the title, including a Databricks logo and the title text\n",
    "title_html = \"<h1 style='text-align: center; display: flex; align-items: center;'>\"\n",
    "title_html += \"<a href='https://seekvectorlogo.com/databricks-vector-logo-svg/' target='_blank'>\"\n",
    "title_html += \"<img src='https://seekvectorlogo.com/wp-content/uploads/2022/02/databricks-vector-logo-2022.png' style='width: 100px; height: auto; margin-right: 10px;' />\"\n",
    "title_html += \"</a>\"\n",
    "title_html += \"LLM Powered Insurance Chatbot built with RAG architecture\"\n",
    "title_html += \"</h1>\"\n",
    "\n",
    "# HTML content for the subtitle\n",
    "subtitle_html = \"<p style='text-align: center;'>AI Chatbot helping customers answering insurance related questions </p>\"\n",
    "\n",
    "# Create and launch the Gradio interface\n",
    "gr.Interface(\n",
    "    fn=question_answer,\n",
    "    inputs=[\"text\", gr.Image(value='https://raw.githubusercontent.com/databricks-industry-solutions/hls-llm-doc-qa/hls-llm-qa-gpu/images/solution-overview.jpeg')],\n",
    "    outputs=[\n",
    "        gr.Textbox(label='Chatbot Response'),\n",
    "        gr.Textbox(label='Document Page#'),\n",
    "        gr.Textbox(label='Document Location'),\n",
    "        gr.Textbox(label='Document Context')\n",
    "    ],\n",
    "    title=title_html + subtitle_html,  # Combine title and subtitle HTML for the interface title\n",
    "    \n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ae238e7-af74-40e2-99ae-701606a07c21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41800204-8882-4b27-8bfd-07d800d8301f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5291d5eb-8b42-48df-9724-a3d8dcfd3ecb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "virtual-insurance-agent",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
